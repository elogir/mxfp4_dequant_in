# MXFP4 Dequantizer

Loader de safetensors et dequantizer de tenseurs MXFP4, en Zig.

Les fonctions sont cens√©es respecter la [spec OCP Microscaling Formats (MX) v1.0](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf).

## Build & Run

N√©cessite Zig 0.15.2 minimum.

```shell
# Build le projet
zig build

# Run le projet
zig build run -- input.safetensors output.safetensors
```

## Tester le code

Le mod√®le de test est `tiny_gpt_oss`, une version all√©g√©e de `gpt_oss`, pour tester rapidement le fonctionnement et comparer avec une version pr√©-dequantiz√©e (notre ref).

Un utilitaire gentiment g√©n√©r√© par un LLM est √† disposition :

```shell
./test.sh
```

Celui-ci :
1. Cr√©e un venv python pour pouvoir plus tard comparer les r√©sultats de la ref √† notre programme
2. Execute notre code sur le mod√®le de test `tiny_gpt_oss`
3. Compare les tenseurs un par un avec le nom (puisque l'ordre a √©t√© chang√©)

## Format MXFP4

MXFP4 stocke des floats sur 4 bits (1 signe, 2 exposant, 1 mantisse). Les tenseurs sont organis√©s en blocks de 32 √©l√©ments, chaque block ayant un facteur d'√©chelle E8M0 (exposant 8-bit, pas de mantisse).

Pour dequantizer :
1. On lit le scale E8M0 du block -> conversion en float32 -> splat
2. Pour chaque √©l√©ment FP4 du block :
   - Conversion FP4 -> float32 via LUT (calcul√©e √† compile-time)
   - Multiplication par la scale (SIMD)

## La logique du Reader

1. Les headers sont pars√©s dans le init de notre Reader, cela permet de pouvoir directement les retourner au premier call.
2. Ensuite √† chaque call, on va read un tenseur et l√† deux cas se pr√©sentent :
    * Si c'est un tenseur non-quantiz√©, on le copie uniquement
    * Si c'est une paire de tenseurs quantiz√©s, on le dequant

    Ensuite on le garde jusqu'√† ce que le caller demande tout le contenu.
3. Fin

## Notes

Ma plus grosse erreur a s√ªrement √©t√© de commencer avec le code sans exposer un `std.Io.Reader` (voir branch non-reader) puis une fois le tout termin√©, tout retransformer en `std.Io.Reader`. Comprendre comment fonctionne le nouvel Io est d√©j√† compliqu√© et manque un peu de guides, mais c'est possible de s'en sortir avec la doc et les sources de la librairie standard (et [la vid√©o de ComputerBread](https://youtu.be/k74veXOMf4U?si=mGi4MI5Gy8DgRTUQ)). Peut-√™tre qu'en partant directement sur l'approche attendue, cela aurait √©t√© plus simple et surtout plus optimal tout en pouvant "override" un max les fonctions de `std.Io.Reader`, o√π du coup, j'utilise l'impl√©mentation de base.

Ma deuxi√®me erreur aura √©t√© mon id√©e de vouloir parser les tenseurs dans le header et dans la data en supportant le fait que les tenseurs de blocks et de scales ne soient pas adjacents, m'obligeant √† parser avec une hashmap pour faire correspondre les paires (plus expliqu√© dans le code) ce qui a bien entendu rendu la t√¢che plus difficile.

J'ai bien test√© sur un safetensors complet de `gpt_oss_20b`, la dequant est successful mais je n'ai pas pu comparer les r√©sultats ni [ouvrir le safetensors pour le parser](https://github.com/by321/safetensors_util), ma machine n'ayant pas assez de RAM... Cependant la taille parait correcte.

Cela √©tant l'un de mes premiers projets Zig, la structure, le flow et les allocations peuvent incontestablement √™tre am√©lior√©s, mais j'aurais d'ici l√† l'occasion de plus pratiquer.

üéâ

